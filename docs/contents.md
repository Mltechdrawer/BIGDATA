# Contents

**Big Data** is structured in two blocks that guide students from the theoretical foundations of complexity and architectures, to the practical aspects of distributed and parallel programming. The aim is to provide the knowledge and skills required to understand, design, and implement scalable and efficient data-intensive applications.

**BLOCK 1. Theoretical Concepts of Big Data** covers complexity management, monitoring and performance engineering, and architectures for Big Data systems. These topics provide the conceptual basis for understanding the challenges of reliability, scalability, and fault tolerance in large-scale data systems.

**BLOCK 2. Distributed and Parallel Programming** introduces the fundamentals of parallel programming, MapReduce, distributed file systems, cluster-oriented application development, and vector programming. These topics consolidate the studentâ€™s ability to design and implement Big Data solutions that exploit parallelism, distribution, and modern computational infrastructures.
